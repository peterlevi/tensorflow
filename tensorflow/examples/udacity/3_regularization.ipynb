{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in _notmist.ipynb_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (200000, 28, 28), (200000,))\n",
      "('Validation set', (10000, 28, 28), (10000,))\n",
      "('Test set', (10000, 28, 28), (10000,))\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set', (200000, 784), (200000, 10))\n",
      "('Validation set', (10000, 784), (10000, 10))\n",
      "('Test set', (10000, 784), (10000, 10))\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 2 to [0.0, 1.0, 0.0 ...], 3 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compue the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "train_subset = 10000\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  # Load the training, validation and test data into constants that are\n",
    "  # attached to the graph.\n",
    "  tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "  tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  # These are the parameters that we are going to be training. The weight\n",
    "  # matrix will be initialized using random valued following a (truncated)\n",
    "  # normal distribution. The biases get initialized to zero.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  # We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "  # the softmax and cross-entropy (it's one operation in TensorFlow, because\n",
    "  # it's very common, and it can be optimized). We take the average of this\n",
    "  # cross-entropy across all training examples: that's our loss.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels)) + 0.01*tf.nn.l2_loss(weights)\n",
    "  \n",
    "  # Optimizer.\n",
    "  # We are going to find the minimum of this loss using gradient descent.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  # These are not part of training, but merely here so that we can report\n",
    "  # accuracy figures as we train.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 47.304199\n",
      "Training accuracy: 10.8%\n",
      "Validation accuracy: 13.5%\n",
      "Loss at step 100: 11.832731\n",
      "Training accuracy: 73.7%\n",
      "Validation accuracy: 72.8%\n",
      "Loss at step 200: 4.476631\n",
      "Training accuracy: 79.3%\n",
      "Validation accuracy: 77.2%\n",
      "Loss at step 300: 1.979096\n",
      "Training accuracy: 82.3%\n",
      "Validation accuracy: 80.0%\n",
      "Loss at step 400: 1.130128\n",
      "Training accuracy: 83.8%\n",
      "Validation accuracy: 81.5%\n",
      "Loss at step 500: 0.837853\n",
      "Training accuracy: 84.3%\n",
      "Validation accuracy: 82.0%\n",
      "Loss at step 600: 0.736061\n",
      "Training accuracy: 84.3%\n",
      "Validation accuracy: 82.2%\n",
      "Loss at step 700: 0.700307\n",
      "Training accuracy: 84.5%\n",
      "Validation accuracy: 82.2%\n",
      "Loss at step 800: 0.687669\n",
      "Training accuracy: 84.4%\n",
      "Validation accuracy: 82.2%\n",
      "Test accuracy: 88.5%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "    # and get the loss value and the training predictions returned as numpy\n",
    "    # arrays.\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    if (step % 100 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Training accuracy: %.1f%%' % accuracy(\n",
    "        predictions, train_labels[:train_subset, :]))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph_relu = tf.Graph()\n",
    "with graph_relu.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights1 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, 1024]))\n",
    "  biases1 = tf.Variable(tf.zeros([1024]))\n",
    "    \n",
    "  weights2 = tf.Variable(\n",
    "    tf.truncated_normal([1024, num_labels]))\n",
    "  biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "  \n",
    "  # Training computation.\n",
    "  logits1 = tf.matmul(tf_train_dataset, weights1) + biases1\n",
    "  hidden = tf.nn.relu(logits1)\n",
    "  logits2 = tf.matmul(hidden, weights2) + biases2\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits2, tf_train_labels)) + \\\n",
    "    + 0.002*tf.nn.l2_loss(weights1) \\\n",
    "    + 0.002*tf.nn.l2_loss(weights2)\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits2)\n",
    "  valid_prediction1 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(valid_prediction1, weights2) + biases2)\n",
    "  test_prediction1 = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "  test_prediction = tf.nn.softmax(\n",
    "    tf.matmul(test_prediction1, weights2) + biases2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 951.844177\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 29.1%\n",
      "Minibatch loss at step 500: 231.251831\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 1000: 83.372635\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 83.4%\n",
      "Minibatch loss at step 1500: 30.945084\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.9%\n",
      "Minibatch loss at step 2000: 11.577959\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 2500: 4.624061\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 3000: 2.069727\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.4%\n",
      "Test accuracy: 92.9%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "with tf.Session(graph=graph_relu) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "graph_relu = tf.Graph()\n",
    "with graph_relu.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights1 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, 200]))\n",
    "  biases1 = tf.Variable(tf.zeros([200]))\n",
    "    \n",
    "  weights2 = tf.Variable(\n",
    "    tf.truncated_normal([200, 50]))\n",
    "  biases2 = tf.Variable(tf.zeros([50]))\n",
    "    \n",
    "  weights3 = tf.Variable(\n",
    "    tf.truncated_normal([50, num_labels]))\n",
    "  biases3 = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "  \n",
    "  # Training computation.\n",
    "  logits1 = tf.matmul(tf_train_dataset, weights1) + biases1\n",
    "  hidden = tf.nn.relu(logits1)\n",
    "  logits2 = tf.matmul(hidden, weights2) + biases2\n",
    "  hidden2 = tf.nn.relu(logits2)\n",
    "  logits3 = tf.matmul(hidden2, weights3) + biases3\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits3, tf_train_labels)) + \\\n",
    "    + 0.001*tf.nn.l2_loss(weights1) \\\n",
    "    + 0.001*tf.nn.l2_loss(weights2) \\\n",
    "    + 0.001*tf.nn.l2_loss(weights3) \\\n",
    "  \n",
    "\n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "  #global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  #learning_rate = tf.train.exponential_decay(0.5, global_step, 1000, 0.8)\n",
    "  #optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits3)\n",
    "  valid_prediction1 = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "  valid_prediction2 = tf.nn.relu(tf.matmul(valid_prediction1, weights2) + biases2)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(valid_prediction2, weights3) + biases3)\n",
    "  test_prediction1 = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "  test_prediction2 = tf.nn.relu(tf.matmul(test_prediction1, weights2) + biases2)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(test_prediction2, weights3) + biases3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "loss =  551.71\n",
      "Minibatch loss at step 0: 551.709900\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 10.6%\n",
      "loss =  99.8806\n",
      "loss =  98.9292\n",
      "loss =  98.8434\n",
      "loss =  98.2408\n",
      "loss =  97.736\n",
      "loss =  97.4465\n",
      "loss =  97.0588\n",
      "loss =  98.6389\n",
      "loss =  96.4091\n",
      "loss =  96.0047\n",
      "loss =  95.584\n",
      "loss =  95.298\n",
      "loss =  94.9393\n",
      "loss =  94.4616\n",
      "loss =  94.0863\n",
      "loss =  93.857\n",
      "loss =  93.433\n",
      "loss =  93.0614\n",
      "loss =  92.6503\n",
      "loss =  92.356\n",
      "loss =  91.8673\n",
      "loss =  91.6079\n",
      "loss =  91.215\n",
      "loss =  90.8931\n",
      "loss =  90.5162\n",
      "loss =  90.4295\n",
      "loss =  89.7708\n",
      "loss =  89.4817\n",
      "loss =  89.128\n",
      "loss =  88.7574\n",
      "loss =  88.4636\n",
      "loss =  88.0977\n",
      "loss =  87.646\n",
      "loss =  87.2991\n",
      "loss =  86.9824\n",
      "loss =  86.7312\n",
      "loss =  86.3237\n",
      "loss =  85.9761\n",
      "loss =  85.6617\n",
      "loss =  85.3093\n",
      "loss =  84.9841\n",
      "loss =  84.6826\n",
      "loss =  84.3233\n",
      "loss =  83.9562\n",
      "loss =  83.6765\n",
      "loss =  83.3466\n",
      "loss =  83.0161\n",
      "loss =  83.0728\n",
      "loss =  82.3031\n",
      "loss =  82.0566\n",
      "Minibatch loss at step 500: 82.056610\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 16.4%\n",
      "loss =  81.763\n",
      "loss =  81.4645\n",
      "loss =  81.0903\n",
      "loss =  80.7659\n",
      "loss =  80.544\n",
      "loss =  80.1309\n",
      "loss =  79.8875\n",
      "loss =  79.5429\n",
      "loss =  79.2501\n",
      "loss =  78.8884\n",
      "loss =  78.648\n",
      "loss =  78.3798\n",
      "loss =  78.1105\n",
      "loss =  77.5946\n",
      "loss =  77.3952\n",
      "loss =  77.0723\n",
      "loss =  76.8575\n",
      "loss =  76.4275\n",
      "loss =  76.079\n",
      "loss =  75.8451\n",
      "loss =  75.5685\n",
      "loss =  75.3517\n",
      "loss =  75.05\n",
      "loss =  74.6995\n",
      "loss =  74.3683\n",
      "loss =  74.0636\n",
      "loss =  73.8743\n",
      "loss =  73.6128\n",
      "loss =  73.3329\n",
      "loss =  73.0679\n",
      "loss =  72.7465\n",
      "loss =  72.3888\n",
      "loss =  72.1566\n",
      "loss =  71.8988\n",
      "loss =  71.5349\n",
      "loss =  71.3326\n",
      "loss =  71.0359\n",
      "loss =  71.026\n",
      "loss =  70.4879\n",
      "loss =  70.2411\n",
      "loss =  69.8482\n",
      "loss =  69.7149\n",
      "loss =  69.3624\n",
      "loss =  69.1562\n",
      "loss =  68.7606\n",
      "loss =  68.5549\n",
      "loss =  68.3803\n",
      "loss =  68.0445\n",
      "loss =  67.8025\n",
      "loss =  67.5182\n",
      "Minibatch loss at step 1000: 67.518196\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 17.8%\n",
      "loss =  67.2225\n",
      "loss =  66.968\n",
      "loss =  66.6654\n",
      "loss =  66.3946\n",
      "loss =  66.2102\n",
      "loss =  65.9654\n",
      "loss =  65.7363\n",
      "loss =  65.4636\n",
      "loss =  65.1189\n",
      "loss =  64.9413\n",
      "loss =  64.6215\n",
      "loss =  64.4137\n",
      "loss =  64.0803\n",
      "loss =  63.8726\n",
      "loss =  63.6572\n",
      "loss =  63.3914\n",
      "loss =  63.2119\n",
      "loss =  62.9973\n",
      "loss =  62.6743\n",
      "loss =  62.5846\n",
      "loss =  62.231\n",
      "loss =  61.9394\n",
      "loss =  61.7444\n",
      "loss =  61.4112\n",
      "loss =  61.2384\n",
      "loss =  60.9499\n",
      "loss =  60.859\n",
      "loss =  60.5966\n",
      "loss =  60.3197\n",
      "loss =  60.2086\n",
      "loss =  59.7923\n",
      "loss =  59.5715\n",
      "loss =  59.3484\n",
      "loss =  59.0812\n",
      "loss =  58.906\n",
      "loss =  58.63\n",
      "loss =  58.388\n",
      "loss =  58.2045\n",
      "loss =  58.0155\n",
      "loss =  57.821\n",
      "loss =  57.6033\n",
      "loss =  57.3998\n",
      "loss =  57.166\n",
      "loss =  56.925\n",
      "loss =  56.6515\n",
      "loss =  56.4974\n",
      "loss =  56.2056\n",
      "loss =  55.9936\n",
      "loss =  55.8334\n",
      "loss =  55.582\n",
      "Minibatch loss at step 1500: 55.582039\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 19.9%\n",
      "loss =  55.4575\n",
      "loss =  55.5258\n",
      "loss =  55.0335\n",
      "loss =  54.8601\n",
      "loss =  54.6819\n",
      "loss =  54.3595\n",
      "loss =  54.1855\n",
      "loss =  54.041\n",
      "loss =  53.8179\n",
      "loss =  53.4604\n",
      "loss =  53.3627\n",
      "loss =  53.0269\n",
      "loss =  52.937\n",
      "loss =  52.7296\n",
      "loss =  52.5445\n",
      "loss =  52.3049\n",
      "loss =  52.2419\n",
      "loss =  51.8463\n",
      "loss =  51.9707\n",
      "loss =  51.3863\n",
      "loss =  51.2165\n",
      "loss =  51.1091\n",
      "loss =  50.8\n",
      "loss =  50.5561\n",
      "loss =  50.4912\n",
      "loss =  50.154\n",
      "loss =  50.0619\n",
      "loss =  49.8474\n",
      "loss =  49.785\n",
      "loss =  49.5681\n",
      "loss =  49.2621\n",
      "loss =  49.4428\n",
      "loss =  48.8966\n",
      "loss =  48.7271\n",
      "loss =  48.552\n",
      "loss =  48.338\n",
      "loss =  48.0008\n",
      "loss =  47.8287\n",
      "loss =  47.7253\n",
      "loss =  47.7021\n",
      "loss =  47.5019\n",
      "loss =  47.343\n",
      "loss =  46.9845\n",
      "loss =  47.0059\n",
      "loss =  46.7872\n",
      "loss =  46.4544\n",
      "loss =  46.3579\n",
      "loss =  46.221\n",
      "loss =  45.984\n",
      "loss =  45.9014\n",
      "Minibatch loss at step 2000: 45.901421\n",
      "Minibatch accuracy: 21.1%\n",
      "Validation accuracy: 21.9%\n",
      "loss =  45.6834\n",
      "loss =  49.2054\n",
      "loss =  45.5589\n",
      "loss =  45.1735\n",
      "loss =  45.1276\n",
      "loss =  44.8927\n",
      "loss =  44.6398\n",
      "loss =  44.6572\n",
      "loss =  44.3255\n",
      "loss =  44.0978\n",
      "loss =  44.0043\n",
      "loss =  43.6728\n",
      "loss =  43.6477\n",
      "loss =  43.4802\n",
      "loss =  43.2771\n",
      "loss =  43.0653\n",
      "loss =  43.0099\n",
      "loss =  42.8476\n",
      "loss =  42.6618\n",
      "loss =  42.4975\n",
      "loss =  42.3412\n",
      "loss =  42.2106\n",
      "loss =  42.0792\n",
      "loss =  41.751\n",
      "loss =  41.7889\n",
      "loss =  41.3597\n",
      "loss =  41.3549\n",
      "loss =  41.2062\n",
      "loss =  41.1452\n",
      "loss =  40.9972\n",
      "loss =  40.6362\n",
      "loss =  40.6237\n",
      "loss =  40.377\n",
      "loss =  40.2866\n",
      "loss =  39.9308\n",
      "loss =  39.9564\n",
      "loss =  39.7376\n",
      "loss =  39.6138\n",
      "loss =  39.5383\n",
      "loss =  39.388\n",
      "loss =  39.297\n",
      "loss =  39.0608\n",
      "loss =  38.9266\n",
      "loss =  38.6357\n",
      "loss =  38.5436\n",
      "loss =  38.4767\n",
      "loss =  38.357\n",
      "loss =  38.1906\n",
      "loss =  38.0282\n",
      "loss =  38.923\n",
      "Minibatch loss at step 2500: 38.922977\n",
      "Minibatch accuracy: 18.8%\n",
      "Validation accuracy: 22.5%\n",
      "loss =  37.7171\n",
      "loss =  37.5887\n",
      "loss =  37.3229\n",
      "loss =  37.3637\n",
      "loss =  37.1311\n",
      "loss =  37.0159\n",
      "loss =  36.9462\n",
      "loss =  36.8642\n",
      "loss =  36.7921\n",
      "loss =  36.4842\n",
      "loss =  36.3039\n",
      "loss =  36.5528\n",
      "loss =  36.0496\n",
      "loss =  36.0507\n",
      "loss =  35.7536\n",
      "loss =  35.5862\n",
      "loss =  35.5673\n",
      "loss =  35.3177\n",
      "loss =  35.1288\n",
      "loss =  34.9937\n",
      "loss =  34.7288\n",
      "loss =  34.7985\n",
      "loss =  34.788\n",
      "loss =  34.7686\n",
      "loss =  34.3538\n",
      "loss =  34.0573\n",
      "loss =  34.2149\n",
      "loss =  33.9683\n",
      "loss =  33.7462\n",
      "loss =  33.9025\n",
      "loss =  33.6276\n",
      "loss =  33.4073\n",
      "loss =  33.302\n",
      "loss =  33.2775\n",
      "loss =  33.0044\n",
      "loss =  32.9862\n",
      "loss =  32.7826\n",
      "loss =  32.8576\n",
      "loss =  32.5038\n",
      "loss =  32.4591\n",
      "loss =  32.1617\n",
      "loss =  32.0526\n",
      "loss =  32.0474\n",
      "loss =  31.8241\n",
      "loss =  31.6684\n",
      "loss =  31.7454\n",
      "loss =  31.6514\n",
      "loss =  31.6405\n",
      "loss =  31.3797\n",
      "loss =  31.2289\n",
      "Minibatch loss at step 3000: 31.228878\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 30.1%\n",
      "loss =  31.1726\n",
      "loss =  30.8417\n",
      "loss =  30.7949\n",
      "loss =  30.6413\n",
      "loss =  30.5247\n",
      "loss =  30.788\n",
      "loss =  30.7016\n",
      "loss =  30.2022\n",
      "loss =  30.0592\n",
      "loss =  29.9933\n",
      "loss =  29.9625\n",
      "loss =  29.7451\n",
      "loss =  29.9144\n",
      "loss =  29.5914\n",
      "loss =  29.4231\n",
      "loss =  29.2827\n",
      "loss =  29.1162\n",
      "loss =  29.1882\n",
      "loss =  28.8907\n",
      "loss =  28.7997\n",
      "loss =  28.7387\n",
      "loss =  28.3746\n",
      "loss =  28.53\n",
      "loss =  28.6317\n",
      "loss =  28.5306\n",
      "loss =  28.2478\n",
      "loss =  28.4269\n",
      "loss =  28.3045\n",
      "loss =  27.9449\n",
      "loss =  27.7568\n",
      "loss =  27.657\n",
      "loss =  27.6448\n",
      "loss =  27.4701\n",
      "loss =  27.7419\n",
      "loss =  27.5488\n",
      "loss =  27.2168\n",
      "loss =  27.0649\n",
      "loss =  27.0777\n",
      "loss =  26.8255\n",
      "loss =  26.8809\n",
      "loss =  26.6526\n",
      "loss =  26.4686\n",
      "loss =  26.4131\n",
      "loss =  26.2095\n",
      "loss =  26.2659\n",
      "loss =  26.0186\n",
      "loss =  26.242\n",
      "loss =  25.9601\n",
      "loss =  25.928\n",
      "loss =  25.5147\n",
      "Minibatch loss at step 3500: 25.514687\n",
      "Minibatch accuracy: 46.1%\n",
      "Validation accuracy: 36.6%\n",
      "loss =  25.8338\n",
      "loss =  25.4168\n",
      "loss =  25.351\n",
      "loss =  25.6577\n",
      "loss =  25.2743\n",
      "loss =  25.1823\n",
      "loss =  25.0726\n",
      "loss =  24.9531\n",
      "loss =  24.9204\n",
      "loss =  24.7142\n",
      "loss =  24.8455\n",
      "loss =  24.774\n",
      "loss =  24.3395\n",
      "loss =  24.4606\n",
      "loss =  24.4875\n",
      "loss =  24.1906\n",
      "loss =  24.3685\n",
      "loss =  23.8621\n",
      "loss =  23.7918\n",
      "loss =  24.4922\n",
      "loss =  23.8192\n",
      "loss =  23.5898\n",
      "loss =  23.5613\n",
      "loss =  23.5816\n",
      "loss =  23.6102\n",
      "loss =  23.0797\n",
      "loss =  23.2252\n",
      "loss =  23.3166\n",
      "loss =  23.0542\n",
      "loss =  23.0789\n",
      "loss =  22.9493\n",
      "loss =  22.891\n",
      "loss =  22.6702\n",
      "loss =  22.6\n",
      "loss =  22.6642\n",
      "loss =  22.4177\n",
      "loss =  22.2883\n",
      "loss =  22.3225\n",
      "loss =  22.0977\n",
      "loss =  22.1469\n",
      "loss =  21.9982\n",
      "loss =  22.0341\n",
      "loss =  21.6841\n",
      "loss =  21.8735\n",
      "loss =  21.632\n",
      "loss =  21.6896\n",
      "loss =  21.3787\n",
      "loss =  21.4682\n",
      "loss =  21.2236\n",
      "loss =  21.1453\n",
      "Minibatch loss at step 4000: 21.145290\n",
      "Minibatch accuracy: 47.7%\n",
      "Validation accuracy: 43.1%\n",
      "loss =  21.032\n",
      "loss =  21.0246\n",
      "loss =  20.8063\n",
      "loss =  20.9185\n",
      "loss =  20.6723\n",
      "loss =  20.8024\n",
      "loss =  20.8372\n",
      "loss =  20.6631\n",
      "loss =  20.4828\n",
      "loss =  20.4783\n",
      "loss =  20.1414\n",
      "loss =  20.1519\n",
      "loss =  20.0281\n",
      "loss =  19.8987\n",
      "loss =  19.9221\n",
      "loss =  19.876\n",
      "loss =  19.6116\n",
      "loss =  19.6211\n",
      "loss =  19.446\n",
      "loss =  19.3906\n",
      "loss =  20.0659\n",
      "loss =  19.5828\n",
      "loss =  18.9852\n",
      "loss =  19.2018\n",
      "loss =  18.9555\n",
      "loss =  19.0036\n",
      "loss =  18.9204\n",
      "loss =  18.7816\n",
      "loss =  18.7176\n",
      "loss =  18.5484\n",
      "loss =  18.6147\n",
      "loss =  18.47\n",
      "loss =  18.3428\n",
      "loss =  18.4002\n",
      "loss =  18.4513\n",
      "loss =  18.4327\n",
      "loss =  18.2083\n",
      "loss =  18.0447\n",
      "loss =  18.07\n",
      "loss =  17.6687\n",
      "loss =  17.7774\n",
      "loss =  17.951\n",
      "loss =  17.4965\n",
      "loss =  17.7097\n",
      "loss =  17.5753\n",
      "loss =  17.5973\n",
      "loss =  17.2827\n",
      "loss =  17.5949\n",
      "loss =  17.285\n",
      "loss =  17.6831\n",
      "Minibatch loss at step 4500: 17.683060\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 60.0%\n",
      "loss =  16.9706\n",
      "loss =  17.0289\n",
      "loss =  16.9778\n",
      "loss =  17.1177\n",
      "loss =  17.1181\n",
      "loss =  17.0169\n",
      "loss =  17.402\n",
      "loss =  16.7407\n",
      "loss =  16.6584\n",
      "loss =  16.446\n",
      "loss =  16.3855\n",
      "loss =  16.466\n",
      "loss =  16.2799\n",
      "loss =  16.2944\n",
      "loss =  16.086\n",
      "loss =  16.1976\n",
      "loss =  16.1548\n",
      "loss =  15.8372\n",
      "loss =  16.0398\n",
      "loss =  15.9144\n",
      "loss =  15.8579\n",
      "loss =  15.8451\n",
      "loss =  15.6498\n",
      "loss =  15.8398\n",
      "loss =  15.4981\n",
      "loss =  15.3594\n",
      "loss =  15.6708\n",
      "loss =  15.318\n",
      "loss =  15.4095\n",
      "loss =  15.2382\n",
      "loss =  15.0766\n",
      "loss =  15.0664\n",
      "loss =  15.2354\n",
      "loss =  14.885\n",
      "loss =  14.6825\n",
      "loss =  14.9431\n",
      "loss =  15.0498\n",
      "loss =  14.7731\n",
      "loss =  14.9086\n",
      "loss =  14.5203\n",
      "loss =  14.6015\n",
      "loss =  14.6388\n",
      "loss =  14.5655\n",
      "loss =  14.3553\n",
      "loss =  14.3439\n",
      "loss =  14.4098\n",
      "loss =  14.1871\n",
      "loss =  14.165\n",
      "loss =  14.2886\n",
      "loss =  14.1109\n",
      "Minibatch loss at step 5000: 14.110931\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 72.1%\n",
      "loss =  13.9827\n",
      "loss =  14.068\n",
      "loss =  13.8514\n",
      "loss =  13.8272\n",
      "loss =  13.9674\n",
      "loss =  13.7203\n",
      "loss =  13.7656\n",
      "loss =  13.6658\n",
      "loss =  13.7965\n",
      "loss =  13.7342\n",
      "loss =  13.5564\n",
      "loss =  13.4713\n",
      "loss =  13.4547\n",
      "loss =  13.2193\n",
      "loss =  13.4553\n",
      "loss =  13.2851\n",
      "loss =  13.3206\n",
      "loss =  13.2325\n",
      "loss =  12.9596\n",
      "loss =  13.2553\n",
      "loss =  12.9324\n",
      "loss =  13.0552\n",
      "loss =  12.7928\n",
      "loss =  13.0447\n",
      "loss =  13.0022\n",
      "loss =  12.934\n",
      "loss =  12.866\n",
      "loss =  12.7358\n",
      "loss =  12.9788\n",
      "loss =  12.4391\n",
      "loss =  12.3484\n",
      "loss =  12.6076\n",
      "loss =  12.512\n",
      "loss =  12.5378\n",
      "loss =  12.278\n",
      "loss =  12.1694\n",
      "loss =  12.3181\n",
      "loss =  12.2363\n",
      "loss =  12.0378\n",
      "loss =  12.2742\n",
      "loss =  11.9845\n",
      "loss =  12.0895\n",
      "loss =  12.0982\n",
      "loss =  11.9842\n",
      "loss =  11.9271\n",
      "loss =  11.7698\n",
      "loss =  11.819\n",
      "loss =  11.8107\n",
      "loss =  11.7723\n",
      "loss =  11.6107\n",
      "Minibatch loss at step 5500: 11.610706\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 75.8%\n",
      "loss =  11.6439\n",
      "loss =  11.5255\n",
      "loss =  11.6444\n",
      "loss =  11.5836\n",
      "loss =  11.4654\n",
      "loss =  11.7426\n",
      "loss =  11.2613\n",
      "loss =  11.0498\n",
      "loss =  11.2162\n",
      "loss =  11.1226\n",
      "loss =  11.2742\n",
      "loss =  11.182\n",
      "loss =  10.9001\n",
      "loss =  10.9678\n",
      "loss =  11.4257\n",
      "loss =  11.0944\n",
      "loss =  11.0035\n",
      "loss =  10.9244\n",
      "loss =  10.8506\n",
      "loss =  10.683\n",
      "loss =  10.6695\n",
      "loss =  10.7636\n",
      "loss =  10.69\n",
      "loss =  10.6459\n",
      "loss =  10.4427\n",
      "loss =  10.5437\n",
      "loss =  10.4642\n",
      "loss =  10.7023\n",
      "loss =  10.5376\n",
      "loss =  10.3272\n",
      "loss =  10.1845\n",
      "loss =  10.5154\n",
      "loss =  10.3732\n",
      "loss =  10.1589\n",
      "loss =  10.4863\n",
      "loss =  10.2086\n",
      "loss =  10.0576\n",
      "loss =  10.1291\n",
      "loss =  10.0169\n",
      "loss =  10.266\n",
      "loss =  9.91466\n",
      "loss =  10.0176\n",
      "loss =  9.86504\n",
      "loss =  9.88378\n",
      "loss =  9.72117\n",
      "loss =  9.65246\n",
      "loss =  9.76864\n",
      "loss =  9.93948\n",
      "loss =  9.74228\n",
      "loss =  9.49809\n",
      "Minibatch loss at step 6000: 9.498094\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 77.8%\n",
      "loss =  9.72305\n",
      "loss =  9.67854\n",
      "loss =  9.33335\n",
      "loss =  9.5484\n",
      "loss =  9.44523\n",
      "loss =  9.47541\n",
      "loss =  9.48462\n",
      "loss =  9.17625\n",
      "loss =  9.30509\n",
      "loss =  9.24764\n",
      "loss =  9.27117\n",
      "loss =  8.95341\n",
      "loss =  9.29473\n",
      "loss =  9.14459\n",
      "loss =  9.09018\n",
      "loss =  9.33204\n",
      "loss =  8.87751\n",
      "loss =  8.98873\n",
      "loss =  9.01901\n",
      "loss =  8.94831\n",
      "loss =  8.98162\n",
      "loss =  8.82172\n",
      "loss =  8.71872\n",
      "loss =  8.55953\n",
      "loss =  8.75485\n",
      "loss =  8.88572\n",
      "loss =  8.72623\n",
      "loss =  8.59356\n",
      "loss =  8.4998\n",
      "loss =  8.50161\n",
      "loss =  8.49269\n",
      "loss =  8.35832\n",
      "loss =  8.58605\n",
      "loss =  8.43598\n",
      "loss =  8.32096\n",
      "loss =  8.3809\n",
      "loss =  8.33557\n",
      "loss =  8.32624\n",
      "loss =  8.39761\n",
      "loss =  8.27102\n",
      "loss =  8.24884\n",
      "loss =  8.09034\n",
      "loss =  8.45938\n",
      "loss =  8.0351\n",
      "loss =  7.82775\n",
      "loss =  8.30501\n",
      "loss =  8.26169\n",
      "loss =  7.88505\n",
      "loss =  7.92912\n",
      "loss =  7.94003\n",
      "Minibatch loss at step 6500: 7.940030\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.0%\n",
      "loss =  8.08198\n",
      "loss =  7.76901\n",
      "loss =  7.84739\n",
      "loss =  7.94543\n",
      "loss =  7.96827\n",
      "loss =  7.6966\n",
      "loss =  7.84333\n",
      "loss =  7.9632\n",
      "loss =  7.64629\n",
      "loss =  7.58675\n",
      "loss =  7.53089\n",
      "loss =  7.59151\n",
      "loss =  7.86893\n",
      "loss =  7.53549\n",
      "loss =  7.5126\n",
      "loss =  7.36502\n",
      "loss =  7.32493\n",
      "loss =  7.40591\n",
      "loss =  7.50339\n",
      "loss =  7.28728\n",
      "loss =  7.29159\n",
      "loss =  7.24169\n",
      "loss =  7.23896\n",
      "loss =  7.24444\n",
      "loss =  7.28776\n",
      "loss =  7.15807\n",
      "loss =  7.32067\n",
      "loss =  7.05859\n",
      "loss =  7.08426\n",
      "loss =  7.06126\n",
      "loss =  7.04692\n",
      "loss =  6.89159\n",
      "loss =  6.88789\n",
      "loss =  6.91247\n",
      "loss =  7.00574\n",
      "loss =  7.11307\n",
      "loss =  6.73553\n",
      "loss =  6.66096\n",
      "loss =  6.7661\n",
      "loss =  6.87305\n",
      "loss =  6.894\n",
      "loss =  6.84924\n",
      "loss =  6.49481\n",
      "loss =  6.6788\n",
      "loss =  6.67963\n",
      "loss =  6.76419\n",
      "loss =  6.7765\n",
      "loss =  6.65671\n",
      "loss =  6.64364\n",
      "loss =  6.57484\n",
      "Minibatch loss at step 7000: 6.574841\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 82.0%\n",
      "loss =  6.54141\n",
      "loss =  6.38869\n",
      "loss =  6.51988\n",
      "loss =  6.59034\n",
      "loss =  6.65704\n",
      "loss =  6.60529\n",
      "loss =  6.36415\n",
      "loss =  6.2265\n",
      "loss =  6.18763\n",
      "loss =  6.19691\n",
      "loss =  6.29488\n",
      "loss =  6.21514\n",
      "loss =  6.39044\n",
      "loss =  6.31352\n",
      "loss =  6.06568\n",
      "loss =  6.19889\n",
      "loss =  6.30025\n",
      "loss =  6.13427\n",
      "loss =  6.07553\n",
      "loss =  6.06929\n",
      "loss =  6.36136\n",
      "loss =  5.91453\n",
      "loss =  5.84847\n",
      "loss =  6.08944\n",
      "loss =  5.98543\n",
      "loss =  5.96413\n",
      "loss =  6.05299\n",
      "loss =  5.84444\n",
      "loss =  5.93738\n",
      "loss =  5.82863\n",
      "loss =  5.93623\n",
      "loss =  5.76351\n",
      "loss =  5.63604\n",
      "loss =  5.65225\n",
      "loss =  5.68761\n",
      "loss =  5.63481\n",
      "loss =  5.63311\n",
      "loss =  5.54922\n",
      "loss =  5.69199\n",
      "loss =  5.66642\n",
      "loss =  5.70523\n",
      "loss =  5.69502\n",
      "loss =  5.41572\n",
      "loss =  5.58053\n",
      "loss =  5.59262\n",
      "loss =  5.54599\n",
      "loss =  5.33902\n",
      "loss =  5.23611\n",
      "loss =  5.41625\n",
      "loss =  5.4341\n",
      "Minibatch loss at step 7500: 5.434096\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 82.9%\n",
      "loss =  5.49605\n",
      "loss =  5.34838\n",
      "loss =  5.36858\n",
      "loss =  5.21843\n",
      "loss =  5.50541\n",
      "loss =  5.19288\n",
      "loss =  5.18599\n",
      "loss =  5.21183\n",
      "loss =  5.12026\n",
      "loss =  5.44425\n",
      "loss =  5.29763\n",
      "loss =  5.15978\n",
      "loss =  5.01737\n",
      "loss =  4.92758\n",
      "loss =  5.19888\n",
      "loss =  5.09494\n",
      "loss =  5.12374\n",
      "loss =  5.0647\n",
      "loss =  5.04374\n",
      "loss =  4.95579\n",
      "loss =  5.12844\n",
      "loss =  4.97022\n",
      "loss =  4.90794\n",
      "loss =  5.08407\n",
      "loss =  5.07104\n",
      "loss =  4.93343\n",
      "loss =  4.89399\n",
      "loss =  4.86675\n",
      "loss =  4.77389\n",
      "loss =  4.71588\n",
      "loss =  4.60723\n",
      "loss =  4.81746\n",
      "loss =  4.68798\n",
      "loss =  4.66591\n",
      "loss =  4.70071\n",
      "loss =  4.77282\n",
      "loss =  4.744\n",
      "loss =  4.73411\n",
      "loss =  4.85095\n",
      "loss =  4.4302\n",
      "loss =  4.6298\n",
      "loss =  4.49595\n",
      "loss =  4.57007\n",
      "loss =  4.70168\n",
      "loss =  4.49756\n",
      "loss =  4.56267\n",
      "loss =  4.562\n",
      "loss =  4.5127\n",
      "loss =  4.55009\n",
      "loss =  4.42022\n",
      "Minibatch loss at step 8000: 4.420215\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.3%\n",
      "loss =  4.28233\n",
      "loss =  4.57016\n",
      "loss =  4.48443\n",
      "loss =  4.37033\n",
      "loss =  4.30264\n",
      "loss =  4.35783\n",
      "loss =  4.42345\n",
      "loss =  4.27569\n",
      "loss =  4.4557\n",
      "loss =  4.50349\n",
      "loss =  4.40048\n",
      "loss =  4.2936\n",
      "loss =  4.15763\n",
      "loss =  4.24659\n",
      "loss =  4.20975\n",
      "loss =  4.18698\n",
      "loss =  4.30568\n",
      "loss =  4.24694\n",
      "loss =  4.2578\n",
      "loss =  4.24506\n",
      "loss =  4.02791\n",
      "loss =  4.20561\n",
      "loss =  4.42542\n",
      "loss =  3.89905\n",
      "loss =  4.08842\n",
      "loss =  4.01991\n",
      "loss =  4.07566\n",
      "loss =  4.07719\n",
      "loss =  3.88876\n",
      "loss =  4.17108\n",
      "loss =  3.93488\n",
      "loss =  3.91719\n",
      "loss =  3.93942\n",
      "loss =  3.94666\n",
      "loss =  3.81398\n",
      "loss =  3.9332\n",
      "loss =  3.84974\n",
      "loss =  3.88238\n",
      "loss =  3.93335\n",
      "loss =  3.90977\n",
      "loss =  3.96381\n",
      "loss =  3.93521\n",
      "loss =  3.78052\n",
      "loss =  3.95539\n",
      "loss =  3.84675\n",
      "loss =  3.78818\n",
      "loss =  3.71538\n",
      "loss =  3.60057\n",
      "loss =  3.69993\n",
      "loss =  3.81653\n",
      "Minibatch loss at step 8500: 3.816535\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 84.7%\n",
      "loss =  3.85775\n",
      "loss =  3.8857\n",
      "loss =  3.75556\n",
      "loss =  3.65576\n",
      "loss =  3.63048\n",
      "loss =  3.64644\n",
      "loss =  3.66855\n",
      "loss =  3.57143\n",
      "loss =  3.65907\n",
      "loss =  3.60127\n",
      "loss =  3.64625\n",
      "loss =  3.44104\n",
      "loss =  3.52484\n",
      "loss =  3.63322\n",
      "loss =  3.43362\n",
      "loss =  3.57997\n",
      "loss =  3.45514\n",
      "loss =  3.70308\n",
      "loss =  3.63983\n",
      "loss =  3.59673\n",
      "loss =  3.53727\n",
      "loss =  3.52812\n",
      "loss =  3.58087\n",
      "loss =  3.3791\n",
      "loss =  3.47241\n",
      "loss =  3.49816\n",
      "loss =  3.37327\n",
      "loss =  3.47649\n",
      "loss =  3.45514\n",
      "loss =  3.50578\n",
      "loss =  3.40567\n",
      "loss =  3.27742\n",
      "loss =  3.3467\n",
      "loss =  3.33957\n",
      "loss =  3.35092\n",
      "loss =  3.30244\n",
      "loss =  3.3725\n",
      "loss =  3.29484\n",
      "loss =  3.27609\n",
      "loss =  3.23166\n",
      "loss =  3.10428\n",
      "loss =  3.2916\n",
      "loss =  3.07763\n",
      "loss =  3.21906\n",
      "loss =  3.34968\n",
      "loss =  3.2003\n",
      "loss =  3.12236\n",
      "loss =  3.17149\n",
      "loss =  3.29256\n",
      "loss =  3.17853\n",
      "Minibatch loss at step 9000: 3.178530\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.4%\n",
      "loss =  3.04588\n",
      "loss =  3.20411\n",
      "loss =  3.10316\n",
      "loss =  3.09804\n",
      "loss =  3.03277\n",
      "loss =  3.05883\n",
      "loss =  3.18435\n",
      "loss =  2.98176\n",
      "loss =  3.10129\n",
      "loss =  3.08575\n",
      "loss =  2.93712\n",
      "loss =  3.00405\n",
      "loss =  3.03222\n",
      "loss =  3.10997\n",
      "loss =  3.09935\n",
      "loss =  3.02257\n",
      "loss =  2.91563\n",
      "loss =  2.79199\n",
      "loss =  2.92522\n",
      "loss =  2.92951\n",
      "loss =  2.95598\n",
      "loss =  2.8803\n",
      "loss =  2.7974\n",
      "loss =  3.15604\n",
      "loss =  2.72664\n",
      "loss =  2.91526\n",
      "loss =  2.84178\n",
      "loss =  2.81483\n",
      "loss =  2.88244\n",
      "loss =  2.86384\n",
      "loss =  2.82342\n",
      "loss =  2.98881\n",
      "loss =  2.84207\n",
      "loss =  2.72237\n",
      "loss =  2.72497\n",
      "loss =  2.73563\n",
      "loss =  2.69542\n",
      "loss =  2.81302\n",
      "loss =  2.87104\n",
      "loss =  2.74029\n",
      "loss =  2.62875\n",
      "loss =  2.80002\n",
      "loss =  2.85474\n",
      "loss =  2.77881\n",
      "loss =  2.67773\n",
      "loss =  2.62074\n",
      "loss =  2.70389\n",
      "loss =  2.70868\n",
      "loss =  2.63628\n",
      "loss =  2.76773\n",
      "Minibatch loss at step 9500: 2.767735\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.8%\n",
      "loss =  2.4851\n",
      "loss =  2.63404\n",
      "loss =  2.76594\n",
      "loss =  2.47842\n",
      "loss =  2.54304\n",
      "loss =  2.47895\n",
      "loss =  2.57054\n",
      "loss =  2.73034\n",
      "loss =  2.65597\n",
      "loss =  2.73522\n",
      "loss =  2.45497\n",
      "loss =  2.79835\n",
      "loss =  2.4527\n",
      "loss =  2.57913\n",
      "loss =  2.47619\n",
      "loss =  2.427\n",
      "loss =  2.53397\n",
      "loss =  2.45965\n",
      "loss =  2.39921\n",
      "loss =  2.32994\n",
      "loss =  2.50679\n",
      "loss =  2.53078\n",
      "loss =  2.42765\n",
      "loss =  2.56894\n",
      "loss =  2.36375\n",
      "loss =  2.47861\n",
      "loss =  2.43332\n",
      "loss =  2.53101\n",
      "loss =  2.35244\n",
      "loss =  2.41128\n",
      "loss =  2.46252\n",
      "loss =  2.42833\n",
      "loss =  2.3275\n",
      "loss =  2.37076\n",
      "loss =  2.32132\n",
      "loss =  2.2566\n",
      "loss =  2.45158\n",
      "loss =  2.35061\n",
      "loss =  2.33387\n",
      "loss =  2.38985\n",
      "loss =  2.19911\n",
      "loss =  2.24728\n",
      "loss =  2.17671\n",
      "loss =  2.15814\n",
      "loss =  2.24585\n",
      "loss =  2.22766\n",
      "loss =  2.24926\n",
      "loss =  2.14656\n",
      "loss =  2.38444\n",
      "loss =  2.31121\n",
      "Minibatch loss at step 10000: 2.311208\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.2%\n",
      "loss =  2.26622\n",
      "loss =  2.18762\n",
      "loss =  2.27221\n",
      "loss =  2.29094\n",
      "loss =  2.33923\n",
      "loss =  2.23887\n",
      "loss =  2.23195\n",
      "loss =  2.20319\n",
      "loss =  2.25554\n",
      "loss =  2.15639\n",
      "loss =  2.29374\n",
      "loss =  2.12246\n",
      "loss =  2.12989\n",
      "loss =  2.21415\n",
      "loss =  2.14545\n",
      "loss =  2.06392\n",
      "loss =  2.29164\n",
      "loss =  2.08347\n",
      "loss =  2.19321\n",
      "loss =  2.14484\n",
      "loss =  2.07071\n",
      "loss =  2.05672\n",
      "loss =  2.10229\n",
      "loss =  2.14008\n",
      "loss =  2.06246\n",
      "loss =  1.9512\n",
      "loss =  2.00235\n",
      "loss =  2.15228\n",
      "loss =  2.05701\n",
      "loss =  1.99917\n",
      "loss =  1.85845\n",
      "loss =  2.02378\n",
      "loss =  1.932\n",
      "loss =  2.18434\n",
      "loss =  2.04441\n",
      "loss =  1.95685\n",
      "loss =  2.11961\n",
      "loss =  2.05838\n",
      "loss =  2.08625\n",
      "loss =  1.93074\n",
      "loss =  1.80181\n",
      "loss =  2.01258\n",
      "loss =  2.09835\n",
      "loss =  2.03059\n",
      "loss =  1.89989\n",
      "loss =  1.94102\n",
      "loss =  2.00958\n",
      "loss =  1.99682\n",
      "loss =  1.98303\n",
      "loss =  1.90821\n",
      "Minibatch loss at step 10500: 1.908214\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.4%\n",
      "loss =  1.85604\n",
      "loss =  1.90197\n",
      "loss =  1.99928\n",
      "loss =  1.97845\n",
      "loss =  1.81886\n",
      "loss =  1.94214\n",
      "loss =  1.87756\n",
      "loss =  1.90375\n",
      "loss =  1.73309\n",
      "loss =  1.83829\n",
      "loss =  1.91206\n",
      "loss =  1.80364\n",
      "loss =  1.93918\n",
      "loss =  2.01454\n",
      "loss =  1.93511\n",
      "loss =  1.87648\n",
      "loss =  2.00915\n",
      "loss =  1.88328\n",
      "loss =  1.83701\n",
      "loss =  1.72308\n",
      "loss =  1.83509\n",
      "loss =  1.65174\n",
      "loss =  1.84669\n",
      "loss =  1.87432\n",
      "loss =  1.71563\n",
      "loss =  1.79662\n",
      "loss =  1.75665\n",
      "loss =  1.77851\n",
      "loss =  1.96443\n",
      "loss =  1.96211\n",
      "loss =  1.7355\n",
      "loss =  1.69899\n",
      "loss =  1.84728\n",
      "loss =  1.74398\n",
      "loss =  1.80293\n",
      "loss =  1.92271\n",
      "loss =  1.76455\n",
      "loss =  1.62328\n",
      "loss =  1.64049\n",
      "loss =  1.61333\n",
      "loss =  1.83777\n",
      "loss =  1.52683\n",
      "loss =  1.60941\n",
      "loss =  1.68119\n",
      "loss =  1.67517\n",
      "loss =  1.67413\n",
      "loss =  1.6888\n",
      "loss =  1.64908\n",
      "loss =  1.66453\n",
      "loss =  1.50454\n",
      "Minibatch loss at step 11000: 1.504544\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.8%\n",
      "loss =  1.5341\n",
      "loss =  1.55392\n",
      "loss =  1.54295\n",
      "loss =  1.58135\n",
      "loss =  1.50406\n",
      "loss =  1.58008\n",
      "loss =  1.58039\n",
      "loss =  1.78067\n",
      "loss =  1.54193\n",
      "loss =  1.59674\n",
      "loss =  1.65495\n",
      "loss =  1.61719\n",
      "loss =  1.69855\n",
      "loss =  1.5334\n",
      "loss =  1.63261\n",
      "loss =  1.637\n",
      "loss =  1.50661\n",
      "loss =  1.63283\n",
      "loss =  1.50957\n",
      "loss =  1.56327\n",
      "loss =  1.41542\n",
      "loss =  1.56991\n",
      "loss =  1.5358\n",
      "loss =  1.57187\n",
      "loss =  1.63764\n",
      "loss =  1.42197\n",
      "loss =  1.39275\n",
      "loss =  1.53266\n",
      "loss =  1.59599\n",
      "loss =  1.73366\n",
      "loss =  1.53677\n",
      "loss =  1.46554\n",
      "loss =  1.42314\n",
      "loss =  1.51678\n",
      "loss =  1.55129\n",
      "loss =  1.67411\n",
      "loss =  1.6774\n",
      "loss =  1.61563\n",
      "loss =  1.47923\n",
      "loss =  1.5028\n",
      "loss =  1.33109\n",
      "loss =  1.35568\n",
      "loss =  1.58745\n",
      "loss =  1.61385\n",
      "loss =  1.46614\n",
      "loss =  1.578\n",
      "loss =  1.39632\n",
      "loss =  1.42663\n",
      "loss =  1.4006\n",
      "loss =  1.54615\n",
      "Minibatch loss at step 11500: 1.546145\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 86.9%\n",
      "loss =  1.32046\n",
      "loss =  1.48642\n",
      "loss =  1.25933\n",
      "loss =  1.27324\n",
      "loss =  1.4618\n",
      "loss =  1.27287\n",
      "loss =  1.47822\n",
      "loss =  1.48239\n",
      "loss =  1.42389\n",
      "loss =  1.39268\n",
      "loss =  1.39098\n",
      "loss =  1.43963\n",
      "loss =  1.51083\n",
      "loss =  1.48066\n",
      "loss =  1.26567\n",
      "loss =  1.40108\n",
      "loss =  1.34455\n",
      "loss =  1.17545\n",
      "loss =  1.32229\n",
      "loss =  1.3681\n",
      "loss =  1.35001\n",
      "loss =  1.30038\n",
      "loss =  1.27503\n",
      "loss =  1.3859\n",
      "loss =  1.38289\n",
      "loss =  1.35764\n",
      "loss =  1.25033\n",
      "loss =  1.36461\n",
      "loss =  1.12736\n",
      "loss =  1.3475\n",
      "loss =  1.36337\n",
      "loss =  1.17163\n",
      "loss =  1.20814\n",
      "loss =  1.30821\n",
      "loss =  1.20327\n",
      "loss =  1.36232\n",
      "loss =  1.41343\n",
      "loss =  1.37429\n",
      "loss =  1.38638\n",
      "loss =  1.38397\n",
      "loss =  1.22442\n",
      "loss =  1.15744\n",
      "loss =  1.31642\n",
      "loss =  1.18247\n",
      "loss =  1.29124\n",
      "loss =  1.26724\n",
      "loss =  1.33024\n",
      "loss =  1.27998\n",
      "loss =  1.2486\n",
      "loss =  1.09709\n",
      "Minibatch loss at step 12000: 1.097094\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 87.5%\n",
      "loss =  1.20836\n",
      "loss =  1.39015\n",
      "loss =  1.16121\n",
      "loss =  1.24896\n",
      "loss =  1.2999\n",
      "loss =  1.11655\n",
      "loss =  1.14884\n",
      "loss =  1.04872\n",
      "loss =  1.11469\n",
      "loss =  1.23348\n",
      "loss =  1.19632\n",
      "loss =  1.19506\n",
      "loss =  1.15567\n",
      "loss =  1.21887\n",
      "loss =  1.23343\n",
      "loss =  1.24785\n",
      "loss =  1.20536\n",
      "loss =  1.32153\n",
      "loss =  1.03025\n",
      "loss =  1.14299\n",
      "loss =  1.13276\n",
      "loss =  1.14984\n",
      "loss =  1.16104\n",
      "loss =  1.27885\n",
      "loss =  1.11471\n",
      "loss =  1.11079\n",
      "loss =  1.17835\n",
      "loss =  1.20242\n",
      "loss =  1.15084\n",
      "loss =  1.15285\n",
      "loss =  1.05068\n",
      "loss =  1.17427\n",
      "loss =  1.25655\n",
      "loss =  1.20899\n",
      "loss =  1.20722\n",
      "loss =  1.15272\n",
      "loss =  1.28268\n",
      "loss =  1.18127\n",
      "loss =  1.05128\n",
      "loss =  1.14803\n",
      "loss =  1.03047\n",
      "loss =  0.981053\n",
      "loss =  1.30693\n",
      "loss =  1.11309\n",
      "loss =  1.0613\n",
      "loss =  1.03946\n",
      "loss =  1.04578\n",
      "loss =  1.04254\n",
      "loss =  1.30255\n",
      "loss =  1.11206\n",
      "Minibatch loss at step 12500: 1.112060\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.5%\n",
      "loss =  1.2634\n",
      "loss =  1.03294\n",
      "loss =  1.16598\n",
      "loss =  0.98999\n",
      "loss =  0.997193\n",
      "loss =  1.15756\n",
      "loss =  1.05533\n",
      "loss =  1.09657\n",
      "loss =  1.02276\n",
      "loss =  1.07835\n",
      "loss =  1.09506\n",
      "loss =  1.22918\n",
      "loss =  1.08984\n",
      "loss =  1.16755\n",
      "loss =  1.06369\n",
      "loss =  1.10746\n",
      "loss =  0.929651\n",
      "loss =  0.983721\n",
      "loss =  1.12634\n",
      "loss =  1.18056\n",
      "loss =  0.988908\n",
      "loss =  1.0142\n",
      "loss =  0.954064\n",
      "loss =  1.00362\n",
      "loss =  0.961856\n",
      "loss =  1.0458\n",
      "loss =  0.885814\n",
      "loss =  1.12425\n",
      "loss =  0.937284\n",
      "loss =  0.958386\n",
      "loss =  1.01398\n",
      "loss =  0.972788\n",
      "loss =  1.04177\n",
      "loss =  1.11676\n",
      "loss =  1.0186\n",
      "loss =  1.08379\n",
      "loss =  0.933329\n",
      "loss =  1.05168\n",
      "loss =  0.965013\n",
      "loss =  0.901344\n",
      "loss =  1.05235\n",
      "loss =  0.896258\n",
      "loss =  1.14131\n",
      "loss =  0.986426\n",
      "loss =  0.858327\n",
      "loss =  1.04297\n",
      "loss =  1.04094\n",
      "loss =  1.17383\n",
      "loss =  0.947101\n",
      "loss =  1.04821\n",
      "Minibatch loss at step 13000: 1.048213\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.0%\n",
      "loss =  1.06909\n",
      "loss =  0.99451\n",
      "loss =  1.02361\n",
      "loss =  1.1117\n",
      "loss =  0.944347\n",
      "loss =  1.03994\n",
      "loss =  0.873341\n",
      "loss =  1.03646\n",
      "loss =  0.980953\n",
      "loss =  0.910949\n",
      "loss =  1.03024\n",
      "loss =  0.902676\n",
      "loss =  0.853889\n",
      "loss =  1.04159\n",
      "loss =  0.88197\n",
      "loss =  1.04006\n",
      "loss =  0.838527\n",
      "loss =  0.848499\n",
      "loss =  1.02291\n",
      "loss =  0.969846\n",
      "loss =  0.903954\n",
      "loss =  0.810109\n",
      "loss =  0.837365\n",
      "loss =  0.972093\n",
      "loss =  1.0251\n",
      "loss =  0.927209\n",
      "loss =  0.880261\n",
      "loss =  0.902493\n",
      "loss =  0.914711\n",
      "loss =  1.11358\n",
      "loss =  0.9085\n",
      "loss =  0.881101\n",
      "loss =  0.90858\n",
      "loss =  0.883355\n",
      "loss =  0.870027\n",
      "loss =  0.793775\n",
      "loss =  0.889246\n",
      "loss =  0.870418\n",
      "loss =  0.901538\n",
      "loss =  0.915043\n",
      "loss =  0.893327\n",
      "loss =  0.978348\n",
      "loss =  0.822049\n",
      "loss =  0.944644\n",
      "loss =  0.827653\n",
      "loss =  0.890037\n",
      "loss =  0.804991\n",
      "loss =  0.782037\n",
      "loss =  0.762608\n",
      "loss =  0.742798\n",
      "Minibatch loss at step 13500: 0.742798\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.2%\n",
      "loss =  0.977937\n",
      "loss =  0.800831\n",
      "loss =  0.828167\n",
      "loss =  0.865554\n",
      "loss =  0.878252\n",
      "loss =  0.815999\n",
      "loss =  0.809926\n",
      "loss =  0.876238\n",
      "loss =  0.730458\n",
      "loss =  0.785552\n",
      "loss =  0.906658\n",
      "loss =  0.856793\n",
      "loss =  0.829997\n",
      "loss =  0.757639\n",
      "loss =  0.825717\n",
      "loss =  0.825198\n",
      "loss =  0.911002\n",
      "loss =  0.80405\n",
      "loss =  0.737832\n",
      "loss =  0.803464\n",
      "loss =  0.908291\n",
      "loss =  0.753616\n",
      "loss =  0.904412\n",
      "loss =  0.780535\n",
      "loss =  0.895873\n",
      "loss =  0.911256\n",
      "loss =  0.831144\n",
      "loss =  0.849523\n",
      "loss =  0.866013\n",
      "loss =  0.857217\n",
      "loss =  0.821737\n",
      "loss =  0.787803\n",
      "loss =  0.923957\n",
      "loss =  0.776203\n",
      "loss =  0.776839\n",
      "loss =  0.813749\n",
      "loss =  0.838399\n",
      "loss =  0.870551\n",
      "loss =  0.821045\n",
      "loss =  0.725088\n",
      "loss =  0.762458\n",
      "loss =  0.774288\n",
      "loss =  0.869709\n",
      "loss =  0.674832\n",
      "loss =  0.742934\n",
      "loss =  0.814686\n",
      "loss =  0.884258\n",
      "loss =  0.763799\n",
      "loss =  1.05339\n",
      "loss =  0.841367\n",
      "Minibatch loss at step 14000: 0.841367\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.2%\n",
      "loss =  0.689269\n",
      "loss =  0.818968\n",
      "loss =  0.807089\n",
      "loss =  0.812999\n",
      "loss =  0.930835\n",
      "loss =  0.812126\n",
      "loss =  0.778374\n",
      "loss =  0.743556\n",
      "loss =  0.773337\n",
      "loss =  0.90513\n",
      "loss =  0.898757\n",
      "loss =  0.772977\n",
      "loss =  0.758283\n",
      "loss =  0.759645\n",
      "loss =  0.654849\n",
      "loss =  0.778898\n",
      "loss =  0.737561\n",
      "loss =  0.758675\n",
      "loss =  0.625114\n",
      "loss =  0.76733\n",
      "loss =  0.6339\n",
      "loss =  0.712485\n",
      "loss =  0.761193\n",
      "loss =  0.813404\n",
      "loss =  0.731439\n",
      "loss =  0.851467\n",
      "loss =  0.663256\n",
      "loss =  0.643284\n",
      "loss =  0.694771\n",
      "loss =  0.858718\n",
      "loss =  0.638709\n",
      "loss =  0.839313\n",
      "loss =  0.767319\n",
      "loss =  0.715144\n",
      "loss =  0.773249\n",
      "loss =  0.743864\n",
      "loss =  0.818715\n",
      "loss =  0.721053\n",
      "loss =  0.750948\n",
      "loss =  0.655227\n",
      "loss =  0.753329\n",
      "loss =  0.749614\n",
      "loss =  0.787021\n",
      "loss =  0.66097\n",
      "loss =  0.786975\n",
      "loss =  0.74462\n",
      "loss =  0.745865\n",
      "loss =  0.623285\n",
      "loss =  0.723131\n",
      "loss =  0.886257\n",
      "Minibatch loss at step 14500: 0.886257\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 88.4%\n",
      "loss =  0.897606\n",
      "loss =  0.661796\n",
      "loss =  0.571223\n",
      "loss =  0.825494\n",
      "loss =  0.740741\n",
      "loss =  0.826928\n",
      "loss =  0.763105\n",
      "loss =  0.645884\n",
      "loss =  0.716104\n",
      "loss =  0.891767\n",
      "loss =  0.623444\n",
      "loss =  0.765901\n",
      "loss =  0.694439\n",
      "loss =  0.710295\n",
      "loss =  0.719202\n",
      "loss =  0.650952\n",
      "loss =  0.790029\n",
      "loss =  0.761605\n",
      "loss =  0.787636\n",
      "loss =  0.763753\n",
      "loss =  0.674943\n",
      "loss =  0.791063\n",
      "loss =  0.677141\n",
      "loss =  0.542849\n",
      "loss =  0.645117\n",
      "loss =  0.639565\n",
      "loss =  0.624032\n",
      "loss =  0.683733\n",
      "loss =  0.774638\n",
      "loss =  0.563937\n",
      "loss =  0.64625\n",
      "loss =  0.680677\n",
      "loss =  0.7486\n",
      "loss =  0.555816\n",
      "loss =  0.561884\n",
      "loss =  0.57373\n",
      "loss =  0.595959\n",
      "loss =  0.743966\n",
      "loss =  0.57987\n",
      "loss =  0.697904\n",
      "loss =  0.60236\n",
      "loss =  0.723477\n",
      "loss =  0.749028\n",
      "loss =  0.715931\n",
      "loss =  0.562929\n",
      "loss =  0.729315\n",
      "loss =  0.619218\n",
      "loss =  0.706597\n",
      "loss =  0.669393\n",
      "loss =  0.750971\n",
      "Minibatch loss at step 15000: 0.750971\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.8%\n",
      "loss =  0.615909\n",
      "loss =  0.720873\n",
      "loss =  0.879135\n",
      "loss =  0.598256\n",
      "loss =  0.639447\n",
      "loss =  0.492322\n",
      "loss =  0.684923\n",
      "loss =  0.705447\n",
      "loss =  0.554537\n",
      "loss =  0.669923\n",
      "loss =  0.598466\n",
      "loss =  0.695234\n",
      "loss =  0.628263\n",
      "loss =  0.659326\n",
      "loss =  0.685715\n",
      "loss =  0.674293\n",
      "loss =  0.650639\n",
      "loss =  0.630051\n",
      "loss =  0.681047\n",
      "loss =  0.675301\n",
      "loss =  0.54762\n",
      "loss =  0.726414\n",
      "loss =  0.730928\n",
      "loss =  0.701027\n",
      "loss =  0.621176\n",
      "loss =  0.691928\n",
      "loss =  0.75954\n",
      "loss =  0.68543\n",
      "loss =  0.504645\n",
      "loss =  0.760218\n",
      "loss =  0.723955\n",
      "loss =  0.705632\n",
      "loss =  0.559225\n",
      "loss =  0.637407\n",
      "loss =  0.616756\n",
      "loss =  0.575355\n",
      "loss =  0.71213\n",
      "loss =  0.599\n",
      "loss =  0.538286\n",
      "loss =  0.587374\n",
      "loss =  0.738766\n",
      "loss =  0.692907\n",
      "loss =  0.736477\n",
      "loss =  0.588943\n",
      "loss =  0.566216\n",
      "loss =  0.674217\n",
      "loss =  0.681938\n",
      "loss =  0.550658\n",
      "loss =  0.620681\n",
      "loss =  0.827142\n",
      "Minibatch loss at step 15500: 0.827142\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.8%\n",
      "loss =  0.686144\n",
      "loss =  0.579043\n",
      "loss =  0.701086\n",
      "loss =  0.583285\n",
      "loss =  0.513146\n",
      "loss =  0.680956\n",
      "loss =  0.527796\n",
      "loss =  0.556044\n",
      "loss =  0.648881\n",
      "loss =  0.627627\n",
      "loss =  0.50917\n",
      "loss =  0.602688\n",
      "loss =  0.720653\n",
      "loss =  0.540323\n",
      "loss =  0.655888\n",
      "loss =  0.71796\n",
      "loss =  0.905666\n",
      "loss =  0.646232\n",
      "loss =  0.580034\n",
      "loss =  0.510453\n",
      "loss =  0.670308\n",
      "loss =  0.749633\n",
      "loss =  0.5801\n",
      "loss =  0.563505\n",
      "loss =  0.536763\n",
      "loss =  0.596038\n",
      "loss =  0.555637\n",
      "loss =  0.547291\n",
      "loss =  0.56556\n",
      "loss =  0.581373\n",
      "loss =  0.585852\n",
      "loss =  0.641878\n",
      "loss =  0.555563\n",
      "loss =  0.651978\n",
      "loss =  0.612906\n",
      "loss =  0.540622\n",
      "loss =  0.621086\n",
      "loss =  0.660263\n",
      "loss =  0.672479\n",
      "loss =  0.629603\n",
      "loss =  0.487192\n",
      "loss =  0.638\n",
      "loss =  0.585381\n",
      "loss =  0.598441\n",
      "loss =  0.517661\n",
      "loss =  0.495302\n",
      "loss =  0.526426\n",
      "loss =  0.585735\n",
      "loss =  0.600274\n",
      "loss =  0.605445\n",
      "Minibatch loss at step 16000: 0.605445\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.5%\n",
      "loss =  0.639255\n",
      "loss =  0.7037\n",
      "loss =  0.618657\n",
      "loss =  0.597049\n",
      "loss =  0.611472\n",
      "loss =  0.551252\n",
      "loss =  0.444261\n",
      "loss =  0.62154\n",
      "loss =  0.469202\n",
      "loss =  0.578922\n",
      "loss =  0.754506\n",
      "loss =  0.483318\n",
      "loss =  0.6364\n",
      "loss =  0.651763\n",
      "loss =  0.554209\n",
      "loss =  0.547414\n",
      "loss =  0.553217\n",
      "loss =  0.667001\n",
      "loss =  0.692042\n",
      "loss =  0.595731\n",
      "loss =  0.534073\n",
      "loss =  0.599085\n",
      "loss =  0.50868\n",
      "loss =  0.585903\n",
      "loss =  0.635353\n",
      "loss =  0.558156\n",
      "loss =  0.555268\n",
      "loss =  0.521942\n",
      "loss =  0.583235\n",
      "loss =  0.664698\n",
      "loss =  0.56452\n",
      "loss =  0.521862\n",
      "loss =  0.646479\n",
      "loss =  0.451187\n",
      "loss =  0.522706\n",
      "loss =  0.537843\n",
      "loss =  0.648658\n",
      "loss =  0.548713\n",
      "loss =  0.6148\n",
      "loss =  0.636916\n",
      "loss =  0.531298\n",
      "loss =  0.749314\n",
      "loss =  0.554008\n",
      "loss =  0.652719\n",
      "loss =  0.525661\n",
      "loss =  0.573074\n",
      "loss =  0.558821\n",
      "loss =  0.683479\n",
      "loss =  0.51931\n",
      "loss =  0.527661\n",
      "Minibatch loss at step 16500: 0.527661\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.8%\n",
      "loss =  0.442516\n",
      "loss =  0.609747\n",
      "loss =  0.619497\n",
      "loss =  0.660102\n",
      "loss =  0.562148\n",
      "loss =  0.466848\n",
      "loss =  0.41924\n",
      "loss =  0.663393\n",
      "loss =  0.632885\n",
      "loss =  0.594478\n",
      "loss =  0.597402\n",
      "loss =  0.616152\n",
      "loss =  0.623199\n",
      "loss =  0.440468\n",
      "loss =  0.44767\n",
      "loss =  0.497677\n",
      "loss =  0.49798\n",
      "loss =  0.425692\n",
      "loss =  0.508712\n",
      "loss =  0.54965\n",
      "loss =  0.490878\n",
      "loss =  0.583222\n",
      "loss =  0.558539\n",
      "loss =  0.42024\n",
      "loss =  0.616292\n",
      "loss =  0.458744\n",
      "loss =  0.597735\n",
      "loss =  0.630756\n",
      "loss =  0.567863\n",
      "loss =  0.609882\n",
      "loss =  0.526715\n",
      "loss =  0.567395\n",
      "loss =  0.572556\n",
      "loss =  0.536288\n",
      "loss =  0.52968\n",
      "loss =  0.537079\n",
      "loss =  0.578758\n",
      "loss =  0.456327\n",
      "loss =  0.519188\n",
      "loss =  0.566221\n",
      "loss =  0.713563\n",
      "loss =  0.546723\n",
      "loss =  0.574614\n",
      "loss =  0.50293\n",
      "loss =  0.647289\n",
      "loss =  0.419163\n",
      "loss =  0.56867\n",
      "loss =  0.599471\n",
      "loss =  0.536076\n",
      "loss =  0.551145\n",
      "Minibatch loss at step 17000: 0.551145\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.6%\n",
      "loss =  0.57996\n",
      "loss =  0.506355\n",
      "loss =  0.607942\n",
      "loss =  0.489499\n",
      "loss =  0.432179\n",
      "loss =  0.477516\n",
      "loss =  0.543558\n",
      "loss =  0.462451\n",
      "loss =  0.53139\n",
      "loss =  0.595003\n",
      "loss =  0.591277\n",
      "loss =  0.618607\n",
      "loss =  0.496782\n",
      "loss =  0.502991\n",
      "loss =  0.544735\n",
      "loss =  0.482722\n",
      "loss =  0.505837\n",
      "loss =  0.539796\n",
      "loss =  0.50805\n",
      "loss =  0.544692\n",
      "loss =  0.401445\n",
      "loss =  0.543434\n",
      "loss =  0.626196\n",
      "loss =  0.563632\n",
      "loss =  0.47804\n",
      "loss =  0.589682\n",
      "loss =  0.536336\n",
      "loss =  0.584743\n",
      "loss =  0.537806\n",
      "loss =  0.602773\n",
      "loss =  0.521738\n",
      "loss =  0.645957\n",
      "loss =  0.534499\n",
      "loss =  0.516317\n",
      "loss =  0.585489\n",
      "loss =  0.520636\n",
      "loss =  0.463332\n",
      "loss =  0.498606\n",
      "loss =  0.523622\n",
      "loss =  0.530512\n",
      "loss =  0.528711\n",
      "loss =  0.425497\n",
      "loss =  0.486936\n",
      "loss =  0.451177\n",
      "loss =  0.412857\n",
      "loss =  0.608044\n",
      "loss =  0.542977\n",
      "loss =  0.615687\n",
      "loss =  0.49251\n",
      "loss =  0.58249\n",
      "Minibatch loss at step 17500: 0.582490\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.8%\n",
      "loss =  0.479793\n",
      "loss =  0.496795\n",
      "loss =  0.586371\n",
      "loss =  0.500233\n",
      "loss =  0.652151\n",
      "loss =  0.56089\n",
      "loss =  0.542134\n",
      "loss =  0.605047\n",
      "loss =  0.492377\n",
      "loss =  0.597064\n",
      "loss =  0.574577\n",
      "loss =  0.451711\n",
      "loss =  0.521703\n",
      "loss =  0.50593\n",
      "loss =  0.541062\n",
      "loss =  0.538729\n",
      "loss =  0.503037\n",
      "loss =  0.476261\n",
      "loss =  0.587\n",
      "loss =  0.406234\n",
      "loss =  0.433368\n",
      "loss =  0.535568\n",
      "loss =  0.525318\n",
      "loss =  0.540097\n",
      "loss =  0.581356\n",
      "loss =  0.62263\n",
      "loss =  0.542008\n",
      "loss =  0.625558\n",
      "loss =  0.535747\n",
      "loss =  0.507995\n",
      "loss =  0.520905\n",
      "loss =  0.54951\n",
      "loss =  0.418323\n",
      "loss =  0.558461\n",
      "loss =  0.515997\n",
      "loss =  0.451934\n",
      "loss =  0.533831\n",
      "loss =  0.706298\n",
      "loss =  0.532246\n",
      "loss =  0.705161\n",
      "loss =  0.651231\n",
      "loss =  0.584214\n",
      "loss =  0.456587\n",
      "loss =  0.429101\n",
      "loss =  0.51188\n",
      "loss =  0.646204\n",
      "loss =  0.486245\n",
      "loss =  0.537592\n",
      "loss =  0.59171\n",
      "loss =  0.458132\n",
      "Minibatch loss at step 18000: 0.458132\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.8%\n",
      "loss =  0.503531\n",
      "loss =  0.654554\n",
      "loss =  0.548613\n",
      "loss =  0.532411\n",
      "loss =  0.458728\n",
      "loss =  0.576441\n",
      "loss =  0.429722\n",
      "loss =  0.449943\n",
      "loss =  0.555948\n",
      "loss =  0.657007\n",
      "loss =  0.452217\n",
      "loss =  0.656871\n",
      "loss =  0.481015\n",
      "loss =  0.528002\n",
      "loss =  0.46539\n",
      "loss =  0.388332\n",
      "loss =  0.572638\n",
      "loss =  0.351026\n",
      "loss =  0.546558\n",
      "loss =  0.541507\n",
      "loss =  0.503738\n",
      "loss =  0.609217\n",
      "loss =  0.539284\n",
      "loss =  0.525315\n",
      "loss =  0.414841\n",
      "loss =  0.483348\n",
      "loss =  0.565676\n",
      "loss =  0.506279\n",
      "loss =  0.383746\n",
      "loss =  0.394305\n",
      "loss =  0.426163\n",
      "loss =  0.4816\n",
      "loss =  0.509367\n",
      "loss =  0.564738\n",
      "loss =  0.523043\n",
      "loss =  0.451242\n",
      "loss =  0.543209\n",
      "loss =  0.610544\n",
      "loss =  0.460031\n",
      "loss =  0.462035\n",
      "loss =  0.420601\n",
      "loss =  0.533358\n",
      "loss =  0.47516\n",
      "loss =  0.511783\n",
      "loss =  0.5425\n",
      "loss =  0.405432\n",
      "loss =  0.501716\n",
      "loss =  0.67025\n",
      "loss =  0.514507\n",
      "loss =  0.436144\n",
      "Minibatch loss at step 18500: 0.436144\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.6%\n",
      "loss =  0.481272\n",
      "loss =  0.411241\n",
      "loss =  0.49812\n",
      "loss =  0.614606\n",
      "loss =  0.476646\n",
      "loss =  0.501281\n",
      "loss =  0.40992\n",
      "loss =  0.520454\n",
      "loss =  0.434746\n",
      "loss =  0.627188\n",
      "loss =  0.513239\n",
      "loss =  0.35314\n",
      "loss =  0.472553\n",
      "loss =  0.435894\n",
      "loss =  0.50841\n",
      "loss =  0.440224\n",
      "loss =  0.467581\n",
      "loss =  0.572491\n",
      "loss =  0.573882\n",
      "loss =  0.608539\n",
      "loss =  0.500916\n",
      "loss =  0.328157\n",
      "loss =  0.486627\n",
      "loss =  0.421127\n",
      "loss =  0.439785\n",
      "loss =  0.521064\n",
      "loss =  0.506531\n",
      "loss =  0.451651\n",
      "loss =  0.474724\n",
      "loss =  0.56073\n",
      "loss =  0.449416\n",
      "loss =  0.536124\n",
      "loss =  0.402557\n",
      "loss =  0.462784\n",
      "loss =  0.329022\n",
      "loss =  0.435508\n",
      "loss =  0.441687\n",
      "loss =  0.383736\n",
      "loss =  0.47698\n",
      "loss =  0.460309\n",
      "loss =  0.444264\n",
      "loss =  0.556123\n",
      "loss =  0.514686\n",
      "loss =  0.413426\n",
      "loss =  0.526898\n",
      "loss =  0.433246\n",
      "loss =  0.433413\n",
      "loss =  0.437883\n",
      "loss =  0.561229\n",
      "loss =  0.564017\n",
      "Minibatch loss at step 19000: 0.564017\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.2%\n",
      "loss =  0.388501\n",
      "loss =  0.591512\n",
      "loss =  0.457951\n",
      "loss =  0.398741\n",
      "loss =  0.44318\n",
      "loss =  0.416979\n",
      "loss =  0.444066\n",
      "loss =  0.553882\n",
      "loss =  0.459278\n",
      "loss =  0.587866\n",
      "loss =  0.42585\n",
      "loss =  0.539776\n",
      "loss =  0.518382\n",
      "loss =  0.536275\n",
      "loss =  0.496233\n",
      "loss =  0.524595\n",
      "loss =  0.44199\n",
      "loss =  0.418436\n",
      "loss =  0.291406\n",
      "loss =  0.371485\n",
      "loss =  0.442731\n",
      "loss =  0.393017\n",
      "loss =  0.450072\n",
      "loss =  0.433245\n",
      "loss =  0.435856\n",
      "loss =  0.428176\n",
      "loss =  0.6558\n",
      "loss =  0.536263\n",
      "loss =  0.545726\n",
      "loss =  0.407947\n",
      "loss =  0.377003\n",
      "loss =  0.524066\n",
      "loss =  0.395472\n",
      "loss =  0.507259\n",
      "loss =  0.574297\n",
      "loss =  0.468117\n",
      "loss =  0.483639\n",
      "loss =  0.384797\n",
      "loss =  0.430098\n",
      "loss =  0.478753\n",
      "loss =  0.406098\n",
      "loss =  0.427559\n",
      "loss =  0.503058\n",
      "loss =  0.567427\n",
      "loss =  0.498779\n",
      "loss =  0.563996\n",
      "loss =  0.464666\n",
      "loss =  0.383551\n",
      "loss =  0.458734\n",
      "loss =  0.403888\n",
      "Minibatch loss at step 19500: 0.403888\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.7%\n",
      "loss =  0.432546\n",
      "loss =  0.586312\n",
      "loss =  0.393202\n",
      "loss =  0.571108\n",
      "loss =  0.417445\n",
      "loss =  0.440908\n",
      "loss =  0.539743\n",
      "loss =  0.439112\n",
      "loss =  0.568825\n",
      "loss =  0.452948\n",
      "loss =  0.506437\n",
      "loss =  0.566409\n",
      "loss =  0.533245\n",
      "loss =  0.507243\n",
      "loss =  0.519559\n",
      "loss =  0.516438\n",
      "loss =  0.337978\n",
      "loss =  0.421952\n",
      "loss =  0.471956\n",
      "loss =  0.393907\n",
      "loss =  0.411181\n",
      "loss =  0.439198\n",
      "loss =  0.46299\n",
      "loss =  0.557661\n",
      "loss =  0.317938\n",
      "loss =  0.451161\n",
      "loss =  0.549656\n",
      "loss =  0.433333\n",
      "loss =  0.408479\n",
      "loss =  0.523755\n",
      "loss =  0.424903\n",
      "loss =  0.509408\n",
      "loss =  0.444586\n",
      "loss =  0.482854\n",
      "loss =  0.422509\n",
      "loss =  0.534786\n",
      "loss =  0.560101\n",
      "loss =  0.46876\n",
      "loss =  0.388543\n",
      "loss =  0.565019\n",
      "loss =  0.475182\n",
      "loss =  0.414487\n",
      "loss =  0.432651\n",
      "loss =  0.474166\n",
      "loss =  0.52033\n",
      "loss =  0.582471\n",
      "loss =  0.486822\n",
      "loss =  0.522106\n",
      "loss =  0.386905\n",
      "Test accuracy: 94.1%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 100000\n",
    "\n",
    "with tf.Session(graph=graph_relu) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        print 'loss = ', l\n",
    "        \n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
